{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d0ab078",
   "metadata": {},
   "source": [
    "#### Training a XGBoost Classifier\n",
    "\n",
    "Our approach was to develop a XGBClassifier to predict the \"NEXT ACTION\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f018003",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sagemaker/base_serializers.py:28: UserWarning: A NumPy version >=1.23.5 and <2.3.0 is required for this version of SciPy (detected version 1.22.4)\n",
      "  import scipy.sparse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.sklearn import SKLearn\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.tuner import HyperparameterTuner, IntegerParameter, CategoricalParameter, ContinuousParameter\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import ast\n",
    "\n",
    "from sagemaker.local import LocalSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7e3e69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "# Local Session\n",
    "#sess = LocalSession()\n",
    "#sess.config = {'local': {'local_code':True}}\n",
    "\n",
    "Bucket = 'sagemaker-us-east-1-254050731868'\n",
    "Prefix = 'starbucks-capstone'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e44a2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = f's3://{Bucket}/{Prefix}/dataset/train.csv'\n",
    "test_path = f's3://{Bucket}/{Prefix}/dataset/test.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5565a7",
   "metadata": {},
   "source": [
    "#### Preparing the estimator for the hyperparameter tuner job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de35a0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = Estimator(entry_point='code/train.py',\n",
    "                      image_uri='683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:1.2-1-cpu-py3',\n",
    "                      instance_count=1,\n",
    "                      instance_type='ml.m5.large',\n",
    "                      #instance_type='local',\n",
    "                      framework_version='1.2-1',\n",
    "                      code_location=f's3://{Bucket}/{Prefix}/model',\n",
    "                      ouptut_path=f's3://{Bucket}/{Prefix}/model',\n",
    "                      dependencies=['code/requirements.txt'],\n",
    "                      role=role,\n",
    "                      max_run=3600,\n",
    "                     )\n",
    "\n",
    "params = {\n",
    "    \"max-depth\":6,         # 0-inf (int)\n",
    "    \"min-child-weight\": 1, # 0-inf (int)\n",
    "    \"subsample\":1,         # 0-1 (float)\n",
    "    \"colsample-bytree\":1,  # 0-1 (float)\n",
    "    \"eta\": 0.3,            # 0-1 (float)\n",
    "}\n",
    "\n",
    "estimator.set_hyperparameters(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c79ca8c",
   "metadata": {},
   "source": [
    "#### Launch the hyperparameter tuner job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3c85f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "now_suffix = now.strftime('%b%d%y-%H%M%S').lower()\n",
    "\n",
    "tuner_args = dict(\n",
    "    objective_metric_name='test_precision',\n",
    "    objective_type='Maximize',\n",
    "    metric_definitions=[{'Name':'test_precision', 'Regex': 'TEST  PRECISION: (-?[0-9\\.]+)'}],\n",
    "    max_jobs=12,\n",
    "    max_parallel_jobs=3,\n",
    "    early_stopping_type='Auto'\n",
    ")\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator=estimator,\n",
    "    hyperparameter_ranges={\n",
    "        \"max-depth\"        : IntegerParameter(2, 400),          # 0-inf (int)\n",
    "        \"min-child-weight\" : IntegerParameter(1, 400),          # 0-inf (int)\n",
    "        \"subsample\"        : ContinuousParameter(0.0001, 0.99), # 0-1 (float)\n",
    "        \"colsample-bytree\" : ContinuousParameter(0.0001, 0.99), # 0-1 (float)\n",
    "        \"eta\"              : ContinuousParameter(0.0001, 0.99)  # 0-1 (float)\n",
    "    },\n",
    "    strategy='Bayesian',\n",
    "    max_runtime_in_seconds=4*3600,\n",
    "    base_tuning_job_name='starbucks',\n",
    "    **tuner_args\n",
    ")\n",
    "\n",
    "tuner.fit(\n",
    "    inputs={'train': train_path, 'test': test_path},\n",
    "    wait=True,\n",
    "    job_name=f'tn-stb-event-{now_suffix}'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecf4002",
   "metadata": {},
   "source": [
    "#### Optionally you can train the final model\n",
    "\n",
    "We prefer this last part to be tested on local to prevent failures of the hyperparameter tunning job rather than training a final model.\n",
    "\n",
    "We could get the final model from our best hyperparameter tunning job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1101963e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: starbucks-sep2124-192622\n",
      "INFO:sagemaker.telemetry.telemetry_logging:SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.\n",
      "To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.\n",
      "INFO:sagemaker.local.image:'Docker Compose' is not installed. Proceeding to check for 'docker-compose' CLI.\n",
      "INFO:sagemaker.local.image:'Docker Compose' found using Docker Compose CLI.\n",
      "INFO:sagemaker.local.local_session:Starting training job\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:sagemaker.local.image:No AWS credentials found in session but credentials from EC2 Metadata Service are available.\n",
      "INFO:sagemaker.local.image:docker compose file: \n",
      "networks:\n",
      "  sagemaker-local:\n",
      "    name: sagemaker-local\n",
      "services:\n",
      "  algo-1-gn0q7:\n",
      "    command: train\n",
      "    container_name: lmx9ecta00-algo-1-gn0q7\n",
      "    environment:\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    image: 683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:1.2-1-cpu-py3\n",
      "    networks:\n",
      "      sagemaker-local:\n",
      "        aliases:\n",
      "        - algo-1-gn0q7\n",
      "    stdin_open: true\n",
      "    tty: true\n",
      "    volumes:\n",
      "    - /tmp/tmpot49xiw7/algo-1-gn0q7/output:/opt/ml/output\n",
      "    - /tmp/tmpot49xiw7/algo-1-gn0q7/input:/opt/ml/input\n",
      "    - /tmp/tmpot49xiw7/algo-1-gn0q7/output/data:/opt/ml/output/data\n",
      "    - /tmp/tmpot49xiw7/model:/opt/ml/model\n",
      "    - /opt/ml/metadata:/opt/ml/metadata\n",
      "    - /tmp/tmpjugwyber:/opt/ml/input/data/train\n",
      "    - /tmp/tmpeox6422u:/opt/ml/input/data/test\n",
      "version: '2.3'\n",
      "\n",
      "INFO:sagemaker.local.image:docker command: docker-compose -f /tmp/tmpot49xiw7/docker-compose.yaml up --build --abort-on-container-exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Container lmx9ecta00-algo-1-gn0q7  Creating\n",
      " Container lmx9ecta00-algo-1-gn0q7  Created\n",
      "Attaching to lmx9ecta00-algo-1-gn0q7\n",
      "lmx9ecta00-algo-1-gn0q7  | 2024-09-21 19:26:24,729 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\n",
      "lmx9ecta00-algo-1-gn0q7  | 2024-09-21 19:26:24,733 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "lmx9ecta00-algo-1-gn0q7  | 2024-09-21 19:26:24,736 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "lmx9ecta00-algo-1-gn0q7  | 2024-09-21 19:26:24,748 sagemaker-training-toolkit INFO     instance_groups entry not present in resource_config\n",
      "lmx9ecta00-algo-1-gn0q7  | 2024-09-21 19:26:24,755 sagemaker_sklearn_container.training INFO     Invoking user training script.\n",
      "lmx9ecta00-algo-1-gn0q7  | 2024-09-21 19:26:25,140 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "lmx9ecta00-algo-1-gn0q7  | /miniconda3/bin/python -m pip install -r requirements.txt\n",
      "lmx9ecta00-algo-1-gn0q7  | Collecting imbalanced-learn==0.10.0 (from -r requirements.txt (line 1))\n",
      "lmx9ecta00-algo-1-gn0q7  |   Downloading imbalanced_learn-0.10.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "lmx9ecta00-algo-1-gn0q7  | Collecting xgboost (from -r requirements.txt (line 2))\n",
      "lmx9ecta00-algo-1-gn0q7  |   Downloading xgboost-2.1.1-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
      "lmx9ecta00-algo-1-gn0q7  | Requirement already satisfied: numpy>=1.17.3 in /miniconda3/lib/python3.8/site-packages (from imbalanced-learn==0.10.0->-r requirements.txt (line 1)) (1.24.1)\n",
      "lmx9ecta00-algo-1-gn0q7  | Requirement already satisfied: scipy>=1.3.2 in /miniconda3/lib/python3.8/site-packages (from imbalanced-learn==0.10.0->-r requirements.txt (line 1)) (1.8.0)\n",
      "lmx9ecta00-algo-1-gn0q7  | Requirement already satisfied: scikit-learn>=1.0.2 in /miniconda3/lib/python3.8/site-packages (from imbalanced-learn==0.10.0->-r requirements.txt (line 1)) (1.2.1)\n",
      "lmx9ecta00-algo-1-gn0q7  | Requirement already satisfied: joblib>=1.1.1 in /miniconda3/lib/python3.8/site-packages (from imbalanced-learn==0.10.0->-r requirements.txt (line 1)) (1.4.2)\n",
      "lmx9ecta00-algo-1-gn0q7  | Requirement already satisfied: threadpoolctl>=2.0.0 in /miniconda3/lib/python3.8/site-packages (from imbalanced-learn==0.10.0->-r requirements.txt (line 1)) (3.5.0)\n",
      "lmx9ecta00-algo-1-gn0q7  | Collecting nvidia-nccl-cu12 (from xgboost->-r requirements.txt (line 2))\n",
      "lmx9ecta00-algo-1-gn0q7  |   Downloading nvidia_nccl_cu12-2.23.4-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "lmx9ecta00-algo-1-gn0q7  | Downloading imbalanced_learn-0.10.0-py3-none-any.whl (225 kB)\n",
      "lmx9ecta00-algo-1-gn0q7  | Downloading xgboost-2.1.1-py3-none-manylinux_2_28_x86_64.whl (153.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.9/153.9 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "lmx9ecta00-algo-1-gn0q7  | \u001b[?25hDownloading nvidia_nccl_cu12-2.23.4-py3-none-manylinux2014_x86_64.whl (199.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.0/199.0 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "lmx9ecta00-algo-1-gn0q7  | \u001b[?25hInstalling collected packages: nvidia-nccl-cu12, xgboost, imbalanced-learn\n",
      "lmx9ecta00-algo-1-gn0q7  | Successfully installed imbalanced-learn-0.10.0 nvidia-nccl-cu12-2.23.4 xgboost-2.1.1\n",
      "lmx9ecta00-algo-1-gn0q7  | 2024-09-21 19:27:07,803 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "lmx9ecta00-algo-1-gn0q7  | 2024-09-21 19:27:07,806 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "lmx9ecta00-algo-1-gn0q7  | 2024-09-21 19:27:07,817 sagemaker-training-toolkit INFO     instance_groups entry not present in resource_config\n",
      "lmx9ecta00-algo-1-gn0q7  | 2024-09-21 19:27:07,830 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "lmx9ecta00-algo-1-gn0q7  | 2024-09-21 19:27:07,833 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "lmx9ecta00-algo-1-gn0q7  | 2024-09-21 19:27:07,844 sagemaker-training-toolkit INFO     instance_groups entry not present in resource_config\n",
      "lmx9ecta00-algo-1-gn0q7  | 2024-09-21 19:27:07,855 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "lmx9ecta00-algo-1-gn0q7  | 2024-09-21 19:27:07,859 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "lmx9ecta00-algo-1-gn0q7  | 2024-09-21 19:27:07,870 sagemaker-training-toolkit INFO     instance_groups entry not present in resource_config\n",
      "lmx9ecta00-algo-1-gn0q7  | 2024-09-21 19:27:07,878 sagemaker-training-toolkit INFO     Invoking user script\n",
      "lmx9ecta00-algo-1-gn0q7  | \n",
      "lmx9ecta00-algo-1-gn0q7  | Training Env:\n",
      "lmx9ecta00-algo-1-gn0q7  | \n",
      "lmx9ecta00-algo-1-gn0q7  | {\n",
      "lmx9ecta00-algo-1-gn0q7  |     \"additional_framework_parameters\": {},\n",
      "lmx9ecta00-algo-1-gn0q7  |     \"channel_input_dirs\": {\n",
      "lmx9ecta00-algo-1-gn0q7  |         \"train\": \"/opt/ml/input/data/train\",\n",
      "lmx9ecta00-algo-1-gn0q7  |         \"test\": \"/opt/ml/input/data/test\"\n",
      "lmx9ecta00-algo-1-gn0q7  |     },\n",
      "lmx9ecta00-algo-1-gn0q7  |     \"current_host\": \"algo-1-gn0q7\",\n",
      "lmx9ecta00-algo-1-gn0q7  |     \"current_instance_group\": \"homogeneousCluster\",\n",
      "lmx9ecta00-algo-1-gn0q7  |     \"current_instance_group_hosts\": [],\n",
      "lmx9ecta00-algo-1-gn0q7  |     \"current_instance_type\": \"local\",\n",
      "lmx9ecta00-algo-1-gn0q7  |     \"distribution_hosts\": [\n",
      "lmx9ecta00-algo-1-gn0q7  |         \"algo-1-gn0q7\"\n",
      "lmx9ecta00-algo-1-gn0q7  |     ],\n",
      "lmx9ecta00-algo-1-gn0q7  |     \"distribution_instance_groups\": [],\n",
      "lmx9ecta00-algo-1-gn0q7  |     \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "lmx9ecta00-algo-1-gn0q7  |     \"hosts\": [\n",
      "lmx9ecta00-algo-1-gn0q7  |         \"algo-1-gn0q7\"\n",
      "lmx9ecta00-algo-1-gn0q7  |     ],\n",
      "lmx9ecta00-algo-1-gn0q7  |     \"hyperparameters\": {},\n",
      "lmx9ecta00-algo-1-gn0q7  |     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "lmx9ecta00-algo-1-gn0q7  |     \"input_data_config\": {\n",
      "lmx9ecta00-algo-1-gn0q7  |         \"train\": {\n",
      "lmx9ecta00-algo-1-gn0q7  |             \"TrainingInputMode\": \"File\"\n",
      "lmx9ecta00-algo-1-gn0q7  |         },\n",
      "lmx9ecta00-algo-1-gn0q7  |         \"test\": {\n",
      "lmx9ecta00-algo-1-gn0q7  |             \"TrainingInputMode\": \"File\"\n",
      "lmx9ecta00-algo-1-gn0q7  |         }\n",
      "lmx9ecta00-algo-1-gn0q7  |     },\n",
      "lmx9ecta00-algo-1-gn0q7  |     \"input_dir\": \"/opt/ml/input\",\n",
      "lmx9ecta00-algo-1-gn0q7  |     \"instance_groups\": [],\n",
      "lmx9ecta00-algo-1-gn0q7  |     \"instance_groups_dict\": {},\n",
      "lmx9ecta00-algo-1-gn0q7  |     \"is_hetero\": false,\n",
      "lmx9ecta00-algo-1-gn0q7  |     \"is_master\": true,\n",
      "lmx9ecta00-algo-1-gn0q7  |     \"is_modelparallel_enabled\": null,\n",
      "lmx9ecta00-algo-1-gn0q7  |     \"is_smddpmprun_installed\": false,\n",
      "lmx9ecta00-algo-1-gn0q7  |     \"is_smddprun_installed\": false,\n",
      "lmx9ecta00-algo-1-gn0q7  |     \"job_name\": \"starbucks-sep2124-192622\",\n",
      "lmx9ecta00-algo-1-gn0q7  |     \"log_level\": 20,\n",
      "lmx9ecta00-algo-1-gn0q7  |     \"master_hostname\": \"algo-1-gn0q7\",\n",
      "lmx9ecta00-algo-1-gn0q7  |     \"model_dir\": \"/opt/ml/model\",\n",
      "lmx9ecta00-algo-1-gn0q7  |     \"module_dir\": \"s3://sagemaker-us-east-1-254050731868/starbucks-sep2124-192622/source/sourcedir.tar.gz\",\n",
      "lmx9ecta00-algo-1-gn0q7  |     \"module_name\": \"train\",\n",
      "lmx9ecta00-algo-1-gn0q7  |     \"network_interface_name\": \"eth0\",\n",
      "lmx9ecta00-algo-1-gn0q7  |     \"num_cpus\": 2,\n",
      "lmx9ecta00-algo-1-gn0q7  |     \"num_gpus\": 0,\n",
      "lmx9ecta00-algo-1-gn0q7  |     \"num_neurons\": 0,\n",
      "lmx9ecta00-algo-1-gn0q7  |     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "lmx9ecta00-algo-1-gn0q7  |     \"output_dir\": \"/opt/ml/output\",\n",
      "lmx9ecta00-algo-1-gn0q7  |     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "lmx9ecta00-algo-1-gn0q7  |     \"resource_config\": {\n",
      "lmx9ecta00-algo-1-gn0q7  |         \"current_host\": \"algo-1-gn0q7\",\n",
      "lmx9ecta00-algo-1-gn0q7  |         \"hosts\": [\n",
      "lmx9ecta00-algo-1-gn0q7  |             \"algo-1-gn0q7\"\n",
      "lmx9ecta00-algo-1-gn0q7  |         ]\n",
      "lmx9ecta00-algo-1-gn0q7  |     },\n",
      "lmx9ecta00-algo-1-gn0q7  |     \"user_entry_point\": \"train.py\"\n",
      "lmx9ecta00-algo-1-gn0q7  | }\n",
      "lmx9ecta00-algo-1-gn0q7  | \n",
      "lmx9ecta00-algo-1-gn0q7  | Environment variables:\n",
      "lmx9ecta00-algo-1-gn0q7  | \n",
      "lmx9ecta00-algo-1-gn0q7  | SM_HOSTS=[\"algo-1-gn0q7\"]\n",
      "lmx9ecta00-algo-1-gn0q7  | SM_NETWORK_INTERFACE_NAME=eth0\n",
      "lmx9ecta00-algo-1-gn0q7  | SM_HPS={}\n",
      "lmx9ecta00-algo-1-gn0q7  | SM_USER_ENTRY_POINT=train.py\n",
      "lmx9ecta00-algo-1-gn0q7  | SM_FRAMEWORK_PARAMS={}\n",
      "lmx9ecta00-algo-1-gn0q7  | SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-gn0q7\",\"hosts\":[\"algo-1-gn0q7\"]}\n",
      "lmx9ecta00-algo-1-gn0q7  | SM_INPUT_DATA_CONFIG={\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"}}\n",
      "lmx9ecta00-algo-1-gn0q7  | SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "lmx9ecta00-algo-1-gn0q7  | SM_CHANNELS=[\"test\",\"train\"]\n",
      "lmx9ecta00-algo-1-gn0q7  | SM_CURRENT_HOST=algo-1-gn0q7\n",
      "lmx9ecta00-algo-1-gn0q7  | SM_CURRENT_INSTANCE_TYPE=local\n",
      "lmx9ecta00-algo-1-gn0q7  | SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
      "lmx9ecta00-algo-1-gn0q7  | SM_CURRENT_INSTANCE_GROUP_HOSTS=[]\n",
      "lmx9ecta00-algo-1-gn0q7  | SM_INSTANCE_GROUPS=[]\n",
      "lmx9ecta00-algo-1-gn0q7  | SM_INSTANCE_GROUPS_DICT={}\n",
      "lmx9ecta00-algo-1-gn0q7  | SM_DISTRIBUTION_INSTANCE_GROUPS=[]\n",
      "lmx9ecta00-algo-1-gn0q7  | SM_IS_HETERO=false\n",
      "lmx9ecta00-algo-1-gn0q7  | SM_MODULE_NAME=train\n",
      "lmx9ecta00-algo-1-gn0q7  | SM_LOG_LEVEL=20\n",
      "lmx9ecta00-algo-1-gn0q7  | SM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\n",
      "lmx9ecta00-algo-1-gn0q7  | SM_INPUT_DIR=/opt/ml/input\n",
      "lmx9ecta00-algo-1-gn0q7  | SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "lmx9ecta00-algo-1-gn0q7  | SM_OUTPUT_DIR=/opt/ml/output\n",
      "lmx9ecta00-algo-1-gn0q7  | SM_NUM_CPUS=2\n",
      "lmx9ecta00-algo-1-gn0q7  | SM_NUM_GPUS=0\n",
      "lmx9ecta00-algo-1-gn0q7  | SM_NUM_NEURONS=0\n",
      "lmx9ecta00-algo-1-gn0q7  | SM_MODEL_DIR=/opt/ml/model\n",
      "lmx9ecta00-algo-1-gn0q7  | SM_MODULE_DIR=s3://sagemaker-us-east-1-254050731868/starbucks-sep2124-192622/source/sourcedir.tar.gz\n",
      "lmx9ecta00-algo-1-gn0q7  | SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1-gn0q7\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[],\"current_instance_type\":\"local\",\"distribution_hosts\":[\"algo-1-gn0q7\"],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1-gn0q7\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"TrainingInputMode\":\"File\"},\"train\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[],\"instance_groups_dict\":{},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":false,\"job_name\":\"starbucks-sep2124-192622\",\"log_level\":20,\"master_hostname\":\"algo-1-gn0q7\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-254050731868/starbucks-sep2124-192622/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-gn0q7\",\"hosts\":[\"algo-1-gn0q7\"]},\"user_entry_point\":\"train.py\"}\n",
      "lmx9ecta00-algo-1-gn0q7  | SM_USER_ARGS=[]\n",
      "lmx9ecta00-algo-1-gn0q7  | SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "lmx9ecta00-algo-1-gn0q7  | SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "lmx9ecta00-algo-1-gn0q7  | SM_CHANNEL_TEST=/opt/ml/input/data/test\n",
      "lmx9ecta00-algo-1-gn0q7  | PYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\n",
      "lmx9ecta00-algo-1-gn0q7  | \n",
      "lmx9ecta00-algo-1-gn0q7  | Invoking script with the following command:\n",
      "lmx9ecta00-algo-1-gn0q7  | \n",
      "lmx9ecta00-algo-1-gn0q7  | /miniconda3/bin/python train.py\n",
      "lmx9ecta00-algo-1-gn0q7  | \n",
      "lmx9ecta00-algo-1-gn0q7  | \n",
      "lmx9ecta00-algo-1-gn0q7  | 2024-09-21 19:27:07,880 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\n",
      "lmx9ecta00-algo-1-gn0q7  | 2024-09-21 19:27:07,880 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\n",
      "lmx9ecta00-algo-1-gn0q7  | TRAIN PRECISION: 0.595\r\n",
      "lmx9ecta00-algo-1-gn0q7  | TRAIN PRECISION: 0.491\r\n",
      "lmx9ecta00-algo-1-gn0q7  | 2024-09-21 19:27:25,198 sagemaker-containers INFO     Reporting training SUCCESS\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:creating /tmp/tmpot49xiw7/artifacts/output/data\n",
      "INFO:root:copying /tmp/tmpot49xiw7/algo-1-gn0q7/output/success -> /tmp/tmpot49xiw7/artifacts/output\n",
      "INFO:root:copying /tmp/tmpot49xiw7/model/model.joblib -> /tmp/tmpot49xiw7/artifacts/model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lmx9ecta00-algo-1-gn0q7 exited with code 0\n",
      "Aborting on container exit...\n",
      " Container lmx9ecta00-algo-1-gn0q7  Stopping\n",
      " Container lmx9ecta00-algo-1-gn0q7  Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.local.image:===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "now_suffix = now.strftime('%b%d%y-%H%M%S').lower()\n",
    "\n",
    "estimator.fit(\n",
    "    wait = True,\n",
    "    job_name=f'starbucks-{now_suffix}',\n",
    "    inputs={\"train\":train_path, \"test\":test_path}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
